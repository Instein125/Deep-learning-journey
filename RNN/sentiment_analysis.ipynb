{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qtrqUITMiqqm"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import imdb\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, SimpleRNN, Embedding, Flatten"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train,y_train),(X_test,y_test) = imdb.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oB4bLGCRs5hT",
        "outputId": "e412014f-dab4-4ef3-db51-e13bff1c95e2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUPYRplgtEmk",
        "outputId": "096bd04d-af13-4506-ec5b-b2312bc5434c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyMECKu7tZ77",
        "outputId": "eb2bbd3d-0687-4edf-a1ca-85c3c2db3bfa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imdb dataset provide a already tokenized dataset."
      ],
      "metadata": {
        "id": "SRricK4-tNoj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Padding"
      ],
      "metadata": {
        "id": "VGafdTs6tVmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.utils import pad_sequences\n",
        "# X_train = pad_sequences(X_train, padding='post')\n",
        "# X_test = pad_sequences(X_test, padding='post')\n",
        "\n",
        "# Training will be very slow so we are padding to maxlength of 50 only for demostration only\n",
        "from keras.utils import pad_sequences\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=50)\n",
        "X_test = pad_sequences(X_test, padding='post',  maxlen=50)"
      ],
      "metadata": {
        "id": "D_BCf5cXtJae"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6flhi5atpsS",
        "outputId": "c773bd25-1920-4995-b779-aba360ac4a9c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a model with embedding layer"
      ],
      "metadata": {
        "id": "41SF1O8Atvq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(10000,output_dim= 2,input_length= 50))\n",
        "# 10000: This parameter specifies the size of the vocabulary\n",
        "# output_dim=2:Each word or token in the vocabulary will be represented by a vector of size 2 in this case.\n",
        "# input_length=2494: This parameter sets the length of the input sequences that will be fed to the embedding layer.\n",
        "model.add(SimpleRNN(32, return_sequences = False))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwKcC-1UtsAC",
        "outputId": "6b20fada-1acf-4586-e9fa-08695e1728d4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 50, 2)             20000     \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 32)                1120      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,153\n",
            "Trainable params: 21,153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = \"binary_crossentropy\", metrics = [\"accuracy\"], optimizer = \"adam\")\n",
        "history = model.fit(X_train,y_train, epochs = 5, validation_data = (X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMtMi0RQu2EM",
        "outputId": "dbb3d20c-89f3-43f7-805c-88569eb9822c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 53s 65ms/step - loss: 0.6933 - accuracy: 0.5014 - val_loss: 0.6956 - val_accuracy: 0.5000\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 49s 63ms/step - loss: 0.6941 - accuracy: 0.5027 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 50s 63ms/step - loss: 0.6933 - accuracy: 0.4978 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 49s 63ms/step - loss: 0.6931 - accuracy: 0.5045 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 50s 64ms/step - loss: 0.6932 - accuracy: 0.4969 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NG7e5qQQvLTV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}